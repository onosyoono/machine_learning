{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleLogisticRegressionForVectorClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOq4w9Q+3XZQXC8B5UlkKlH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmanPriyanshu/Natural-Language-Processing/blob/master/SimpleLogisticRegressionForVectorClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLbyMDha-s_",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuigFX8YTqbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "225f4f7c-184d-4dde-b207-aea2794a1664"
      },
      "source": [
        "!mkdir -p data\n",
        "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/sentiment140-subset.csv.zip -P data\n",
        "!unzip -n -d data data/sentiment140-subset.csv.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘data/sentiment140-subset.csv.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  data/sentiment140-subset.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrffwTEzAb10",
        "colab_type": "text"
      },
      "source": [
        "## IMPORTS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W2wi3t3AbD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1d60719a-33d6-488f-9d18-c60ae0d15546"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdHHU2ofbNh9",
        "colab_type": "text"
      },
      "source": [
        "### Only importing 30,000 values since this is more of practice and demo for refrence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss6feKisbD5-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "65745154-db3a-4179-ea7d-accc578e66c5"
      },
      "source": [
        "df = pd.read_csv(\"data/sentiment140-subset.csv\", nrows=30000)\n",
        "print(df.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   polarity                                               text\n",
            "0         0                      @kconsidder You never tweet  \n",
            "1         0                 Sick today  coding from the couch.\n",
            "2         1  @ChargerJenn Thx for answering so quick,I was ...\n",
            "3         1  Wii fit says I've lost 10 pounds since last ti...\n",
            "4         0  @MrKinetik Not a thing!!!  I don't really have...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7NJTP6ubYan",
        "colab_type": "text"
      },
      "source": [
        "### Let's count positives and negatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D3_YmC1bUP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "03f9d216-4339-4309-cb1a-5895e2f2d7fe"
      },
      "source": [
        "df.polarity.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    15064\n",
              "0    14936\n",
              "Name: polarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8VA52NBbcSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "38ac9c09-c2ae-4a29-f91d-3c8ab1e12745"
      },
      "source": [
        "df = df.values\n",
        "print(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 '@kconsidder You never tweet  ']\n",
            " [0 'Sick today  coding from the couch.']\n",
            " [1\n",
            "  '@ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that ']\n",
            " ...\n",
            " [1\n",
            "  '@phnompenhpost thanks for the follow! u guys do a great job in reporting news about Cambodia...makes me proud to be cambodian ']\n",
            " [0\n",
            "  \"@coliwilso crapï¿½ I really wanted to make it for @minmï¿½ but I'm feeling way too tired after the whole weekend \"]\n",
            " [1\n",
            "  'follow friday- @theclassiccrime @jeremycamp @chris_daughtry &amp; @dannygokey ']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGvQcacz_zO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "polarity = df.T[0].flatten()\n",
        "tweets = df.T[1].flatten()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSsgWRUXB61H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "ff31d44f-f21b-4ddc-87b8-3e691cdc009e"
      },
      "source": [
        "tweets"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@kconsidder You never tweet  ',\n",
              "       'Sick today  coding from the couch.',\n",
              "       '@ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that ',\n",
              "       ...,\n",
              "       '@phnompenhpost thanks for the follow! u guys do a great job in reporting news about Cambodia...makes me proud to be cambodian ',\n",
              "       \"@coliwilso crapï¿½ I really wanted to make it for @minmï¿½ but I'm feeling way too tired after the whole weekend \",\n",
              "       'follow friday- @theclassiccrime @jeremycamp @chris_daughtry &amp; @dannygokey '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAiZSeGQJPDT",
        "colab_type": "text"
      },
      "source": [
        "## PREPROCESSING:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzOci6zMBeMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stopwords_punctuation(arr):\n",
        "  new_arr = []\n",
        "  diction = {}\n",
        "  for p in string.punctuation:\n",
        "    diction.update({p:' '})\n",
        "  for s in tqdm(arr):\n",
        "    s = s.translate(str.maketrans(diction))\n",
        "    new_arr.append(' '.join([i for i in s.split() if i not in stopwords.words('english')]))\n",
        "  new_arr = np.array(new_arr)\n",
        "  return new_arr"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_VU7KOyAAdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming_lowercase(arr):\n",
        "  porter = PorterStemmer()\n",
        "  stemmed_arr = []\n",
        "  for s in tqdm(arr):\n",
        "    s = s.lower()\n",
        "    stemmed_arr.append(' '.join([porter.stem(word) for word in s.split()]))\n",
        "  stemmed_arr = np.array(stemmed_arr)\n",
        "  return stemmed_arr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEIT8ks2DmM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c0a13ce0-162c-494a-eece-7c52f07f54db"
      },
      "source": [
        "tweets = stopwords_punctuation(tweets)\n",
        "tweets = stemming_lowercase(tweets)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:48<00:00, 613.24it/s]\n",
            "100%|██████████| 30000/30000 [00:04<00:00, 6498.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIR8uG65JRjb",
        "colab_type": "text"
      },
      "source": [
        "## TRAINING FREQUENCIES:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKasnL8XD2Fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_positive_negative_word_counts(polar_arr, str_arr):\n",
        "  word_feature = {}\n",
        "  for p,s in tqdm(zip(polar_arr, str_arr), total=len(str_arr)):\n",
        "    s = s.split()\n",
        "    for w in s:\n",
        "      if w not in list(word_feature.keys()):\n",
        "        word_feature.update({w: [0, 0]})\n",
        "      word_feature[w][p] += 1\n",
        "  return word_feature"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7-8h3eSHZzD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d2da83b-5719-46ba-a35f-8ecd0fca6a1f"
      },
      "source": [
        "word_feature = generate_positive_negative_word_counts(polarity[:int(0.5*polarity.shape[0])], tweets[:int(0.5*polarity.shape[0])])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15000/15000 [00:20<00:00, 722.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zaydwis_JU7E",
        "colab_type": "text"
      },
      "source": [
        "## TWEET to REPRESENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1j_dEeZJLeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tweet2rep(arr, word_feature):\n",
        "  rep = []\n",
        "  for s in tqdm(arr):\n",
        "    p = 0\n",
        "    n = 0\n",
        "    for w in s.split():\n",
        "      try:\n",
        "        p += word_feature[w][1]\n",
        "        n += word_feature[w][0]\n",
        "      except:\n",
        "        pass\n",
        "    rep.append([1, p, n])\n",
        "  rep = np.array(rep)\n",
        "  return rep"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HshrxFOKQ7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "554e3182-cb35-4876-aaf1-d17f745c5e19"
      },
      "source": [
        "representation = tweet2rep(tweets, word_feature)\n",
        "print(representation[:5])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:00<00:00, 190249.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[    1   403   283]\n",
            " [    1   336   508]\n",
            " [    1  8222 11827]\n",
            " [    1  3225  4526]\n",
            " [    1  2947  4256]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNjljmUXKOl7",
        "colab_type": "text"
      },
      "source": [
        "## LOGISTIC REGRESSION:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsvn_2Q_HfoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(2, activation='relu'), \n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid'), \n",
        "                             ])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', 'AUC'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY2GaUTOMHmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "representation = representation.astype('float')\n",
        "polarity = polarity.astype('float')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3kvCA2iJJLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3188756-8446-4e18-dfba-1cfa824376a1"
      },
      "source": [
        "model.fit(representation, polarity, epochs=50, validation_split=0.2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 10.1126 - acc: 0.6049 - auc: 0.5850 - val_loss: 0.9822 - val_acc: 0.5695 - val_auc: 0.5674\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.8658 - acc: 0.5658 - auc: 0.5603 - val_loss: 0.8394 - val_acc: 0.5548 - val_auc: 0.5538\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.7805 - acc: 0.5527 - auc: 0.5613 - val_loss: 0.7639 - val_acc: 0.5443 - val_auc: 0.5445\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.7374 - acc: 0.5440 - auc: 0.5488 - val_loss: 0.7304 - val_acc: 0.5390 - val_auc: 0.5428\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.7197 - acc: 0.5375 - auc: 0.5445 - val_loss: 0.7100 - val_acc: 0.5333 - val_auc: 0.5378\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.7095 - acc: 0.5335 - auc: 0.5378 - val_loss: 0.6975 - val_acc: 0.5300 - val_auc: 0.5336\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.7014 - acc: 0.5290 - auc: 0.5365 - val_loss: 0.6894 - val_acc: 0.5243 - val_auc: 0.5288\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6951 - acc: 0.5257 - auc: 0.5315 - val_loss: 0.6893 - val_acc: 0.5203 - val_auc: 0.5240\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6921 - acc: 0.5225 - auc: 0.5270 - val_loss: 0.6887 - val_acc: 0.5183 - val_auc: 0.5229\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6875 - acc: 0.5204 - auc: 0.5257 - val_loss: 0.6878 - val_acc: 0.5145 - val_auc: 0.5201\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6856 - acc: 0.5177 - auc: 0.5231 - val_loss: 0.6887 - val_acc: 0.5140 - val_auc: 0.5179\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6849 - acc: 0.5167 - auc: 0.5195 - val_loss: 0.6878 - val_acc: 0.5133 - val_auc: 0.5181\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6850 - acc: 0.5165 - auc: 0.5244 - val_loss: 0.6875 - val_acc: 0.5127 - val_auc: 0.5174\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6847 - acc: 0.5153 - auc: 0.5246 - val_loss: 0.6872 - val_acc: 0.5122 - val_auc: 0.5166\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6847 - acc: 0.5120 - auc: 0.5213 - val_loss: 0.6855 - val_acc: 0.5110 - val_auc: 0.5176\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6841 - acc: 0.5128 - auc: 0.5218 - val_loss: 0.6868 - val_acc: 0.5133 - val_auc: 0.5191\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6839 - acc: 0.5168 - auc: 0.5213 - val_loss: 0.6878 - val_acc: 0.5147 - val_auc: 0.5191\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6842 - acc: 0.5163 - auc: 0.5230 - val_loss: 0.6871 - val_acc: 0.5133 - val_auc: 0.5178\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6839 - acc: 0.5179 - auc: 0.5236 - val_loss: 0.6872 - val_acc: 0.5145 - val_auc: 0.5193\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6839 - acc: 0.5171 - auc: 0.5223 - val_loss: 0.6885 - val_acc: 0.5165 - val_auc: 0.5202\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6836 - acc: 0.5196 - auc: 0.5257 - val_loss: 0.6861 - val_acc: 0.5155 - val_auc: 0.5206\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6839 - acc: 0.5198 - auc: 0.5270 - val_loss: 0.6854 - val_acc: 0.5138 - val_auc: 0.5196\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6828 - acc: 0.5176 - auc: 0.5242 - val_loss: 0.6855 - val_acc: 0.5148 - val_auc: 0.5204\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6823 - acc: 0.5185 - auc: 0.5259 - val_loss: 0.6855 - val_acc: 0.5150 - val_auc: 0.5201\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6818 - acc: 0.5188 - auc: 0.5271 - val_loss: 0.6833 - val_acc: 0.5183 - val_auc: 0.5256\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6828 - acc: 0.5200 - auc: 0.5311 - val_loss: 0.6833 - val_acc: 0.5168 - val_auc: 0.5243\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6821 - acc: 0.5196 - auc: 0.5315 - val_loss: 0.6826 - val_acc: 0.5193 - val_auc: 0.5268\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6820 - acc: 0.5220 - auc: 0.5347 - val_loss: 0.6832 - val_acc: 0.5185 - val_auc: 0.5253\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6811 - acc: 0.5253 - auc: 0.5342 - val_loss: 0.6801 - val_acc: 0.5253 - val_auc: 0.5307\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6799 - acc: 0.5295 - auc: 0.5362 - val_loss: 0.6814 - val_acc: 0.5227 - val_auc: 0.5277\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6762 - acc: 0.5364 - auc: 0.5508 - val_loss: 0.6788 - val_acc: 0.5490 - val_auc: 0.5540\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6734 - acc: 0.5568 - auc: 0.5654 - val_loss: 0.6717 - val_acc: 0.5603 - val_auc: 0.5678\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6649 - acc: 0.5730 - auc: 0.5830 - val_loss: 0.6596 - val_acc: 0.5960 - val_auc: 0.6035\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6413 - acc: 0.6398 - auc: 0.6623 - val_loss: 0.6651 - val_acc: 0.5855 - val_auc: 0.6000\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6420 - acc: 0.6351 - auc: 0.6497 - val_loss: 0.6486 - val_acc: 0.6187 - val_auc: 0.6309\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6316 - acc: 0.6594 - auc: 0.6843 - val_loss: 0.6347 - val_acc: 0.6448 - val_auc: 0.6659\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6301 - acc: 0.6559 - auc: 0.6805 - val_loss: 0.6361 - val_acc: 0.6437 - val_auc: 0.6611\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6289 - acc: 0.6577 - auc: 0.6777 - val_loss: 0.6324 - val_acc: 0.6557 - val_auc: 0.6768\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6308 - acc: 0.6568 - auc: 0.6794 - val_loss: 0.6679 - val_acc: 0.6627 - val_auc: 0.6896\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6313 - acc: 0.6529 - auc: 0.6733 - val_loss: 0.6349 - val_acc: 0.6343 - val_auc: 0.6585\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6282 - acc: 0.6575 - auc: 0.6818 - val_loss: 0.6476 - val_acc: 0.6620 - val_auc: 0.6918\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6241 - acc: 0.6647 - auc: 0.6933 - val_loss: 0.6252 - val_acc: 0.6515 - val_auc: 0.6817\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6217 - acc: 0.6582 - auc: 0.7003 - val_loss: 0.6176 - val_acc: 0.6500 - val_auc: 0.6968\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6089 - acc: 0.6600 - auc: 0.7252 - val_loss: 0.6403 - val_acc: 0.6610 - val_auc: 0.7180\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6040 - acc: 0.6650 - auc: 0.7317 - val_loss: 0.6103 - val_acc: 0.6518 - val_auc: 0.7230\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6040 - acc: 0.6563 - auc: 0.7334 - val_loss: 0.6321 - val_acc: 0.5973 - val_auc: 0.6911\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6047 - acc: 0.6556 - auc: 0.7336 - val_loss: 0.6153 - val_acc: 0.6577 - val_auc: 0.7254\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6030 - acc: 0.6592 - auc: 0.7372 - val_loss: 0.6098 - val_acc: 0.6478 - val_auc: 0.7217\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6040 - acc: 0.6604 - auc: 0.7361 - val_loss: 0.6106 - val_acc: 0.6503 - val_auc: 0.7229\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 0.6029 - acc: 0.6637 - auc: 0.7377 - val_loss: 0.6162 - val_acc: 0.6583 - val_auc: 0.7258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5bef48f5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hu0Yvh8OdOh",
        "colab_type": "text"
      },
      "source": [
        "## DONE"
      ]
    }
  ]
}